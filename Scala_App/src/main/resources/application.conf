# RAG Delta Indexer Configuration
app {
  name = "RAG Delta Indexer"
  version = "1.0.0"
}

# Spark Configuration
spark {
  master = "local[*]"  # Change to "yarn" for EMR deployment
  warehouse.dir = "/spark/warehouse"

  # Delta Lake extensions (can be overridden via spark-submit)
  extensions = "io.delta.sql.DeltaSparkSessionExtension"
  catalog = "org.apache.spark.sql.delta.catalog.DeltaCatalog"
}

# Data Source Configuration
data {
  # Source folder containing PDF files
  source.folder = "/spark/data/text_corpus"

  # Local directory for downloading PDFs for text extraction
  downloaded.pdfs.dir = "/tmp/downloaded_pdfs"

  # Snapshot storage configuration
  snapshots {
    base.path = "/spark/index_snapshots"
  }
}

# Embedding Model Configuration
embedding {
  model {
    name = "mxbai-embed-large"
    version = "v1"
  }

  # Batch size for embedding generation
  batch.size = 2

  # Ollama service configuration
  ollama {
    host = "localhost"
    port = 11434
    timeout.seconds = 120
  }
}

# Logging Configuration (optional - mainly for reference)
logging {
  level = "INFO"
  pattern = "%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n"
}

# Environment-specific overrides
# These can be overridden by creating application-dev.conf, application-prod.conf, etc.
environments {
  local {
    data.source.folder = "/spark/data/text_corpus"
    spark.warehouse.dir = "/spark/warehouse"
    data.snapshots.base.path = "/spark/index_snapshots"
  }

  emr {
    spark.master = "yarn"
    data.source.folder = "s3://cs441-incremental-delta-rag/EMR/data/text_corpus/"
    spark.warehouse.dir = "s3://cs441-incremental-delta-rag/EMR/warehouse/"
    data.snapshots.base.path = "s3://cs441-incremental-delta-rag/EMR/index_snapshots/"
  }
}
